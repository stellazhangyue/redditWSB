<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Data transformation | Analysis of stocks discussed in Reddit r/wallstreetbets</title>
  <meta name="description" content="Chapter 3 Data transformation | Analysis of stocks discussed in Reddit r/wallstreetbets" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Data transformation | Analysis of stocks discussed in Reddit r/wallstreetbets" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Data transformation | Analysis of stocks discussed in Reddit r/wallstreetbets" />
  
  
  

<meta name="author" content="Xingyu Lu, Yue Xiong ,Yue Zhang" />


<meta name="date" content="2021-12-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-sources.html"/>
<link rel="next" href="missing-values.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">RedditWSB</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="data-sources.html"><a href="data-sources.html"><i class="fa fa-check"></i><b>2</b> Data sources</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-sources.html"><a href="data-sources.html#stock-dataset"><i class="fa fa-check"></i><b>2.1</b> Stock dataset</a></li>
<li class="chapter" data-level="2.2" data-path="data-sources.html"><a href="data-sources.html#reddit-posts-dataset"><i class="fa fa-check"></i><b>2.2</b> Reddit posts dataset</a></li>
<li class="chapter" data-level="2.3" data-path="data-sources.html"><a href="data-sources.html#google-trends-dataset"><i class="fa fa-check"></i><b>2.3</b> Google Trends dataset</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-transformation.html"><a href="data-transformation.html"><i class="fa fa-check"></i><b>3</b> Data transformation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data-transformation.html"><a href="data-transformation.html#reddit-data-transformation"><i class="fa fa-check"></i><b>3.1</b> Reddit Data Transformation</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="data-transformation.html"><a href="data-transformation.html#parse-stock-tickers-from-reddit-posts"><i class="fa fa-check"></i><b>3.1.1</b> Parse Stock tickers from Reddit posts</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-transformation.html"><a href="data-transformation.html#rwallstreetbets-subreddit-overview"><i class="fa fa-check"></i><b>3.1.2</b> r/wallstreetbets Subreddit Overview</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-transformation.html"><a href="data-transformation.html#reddit-posts-content"><i class="fa fa-check"></i><b>3.1.3</b> Reddit posts content</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-transformation.html"><a href="data-transformation.html#stock-data-transformation"><i class="fa fa-check"></i><b>3.2</b> Stock Data Transformation</a></li>
<li class="chapter" data-level="3.3" data-path="data-transformation.html"><a href="data-transformation.html#google-trends-data-transformation"><i class="fa fa-check"></i><b>3.3</b> Google Trends Data Transformation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>4</b> Missing values</a>
<ul>
<li class="chapter" data-level="4.1" data-path="missing-values.html"><a href="missing-values.html#reddit-post-dataset"><i class="fa fa-check"></i><b>4.1</b> Reddit post dataset</a></li>
<li class="chapter" data-level="4.2" data-path="missing-values.html"><a href="missing-values.html#google-trend-dataset"><i class="fa fa-check"></i><b>4.2</b> Google Trend dataset</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>5</b> Results</a>
<ul>
<li class="chapter" data-level="5.1" data-path="results.html"><a href="results.html#stock-data-and-information"><i class="fa fa-check"></i><b>5.1</b> Stock Data and Information</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="results.html"><a href="results.html#stock-candlestick-plot"><i class="fa fa-check"></i><b>5.1.1</b> Stock Candlestick Plot</a></li>
<li class="chapter" data-level="5.1.2" data-path="results.html"><a href="results.html#stock-risk-assessment"><i class="fa fa-check"></i><b>5.1.2</b> Stock Risk Assessment</a></li>
<li class="chapter" data-level="5.1.3" data-path="results.html"><a href="results.html#most-popular-stocks"><i class="fa fa-check"></i><b>5.1.3</b> Most Popular Stocks</a></li>
<li class="chapter" data-level="5.1.4" data-path="results.html"><a href="results.html#time-series-of-the-top-10-stocks"><i class="fa fa-check"></i><b>5.1.4</b> Time Series of the Top 10 Stocks</a></li>
<li class="chapter" data-level="5.1.5" data-path="results.html"><a href="results.html#correlations-between-top-10-mentioned-stocks"><i class="fa fa-check"></i><b>5.1.5</b> Correlations between top 10 mentioned stocks</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="results.html"><a href="results.html#rwallstreetbets-reddit-post-data"><i class="fa fa-check"></i><b>5.2</b> r/WallStreetBets Reddit Post Data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="results.html"><a href="results.html#rwallstreetbets-metrics"><i class="fa fa-check"></i><b>5.2.1</b> r/WallStreetBets metrics</a></li>
<li class="chapter" data-level="5.2.2" data-path="results.html"><a href="results.html#what-are-the-most-popular-keywords"><i class="fa fa-check"></i><b>5.2.2</b> What are the most popular keywords?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="results.html"><a href="results.html#whats-the-impact-of-rwallstreetbet"><i class="fa fa-check"></i><b>5.3</b> What’s the impact of r/wallstreetbet?</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="results.html"><a href="results.html#reddit-metrics-vs.-stock-price-and-volume"><i class="fa fa-check"></i><b>5.3.1</b> Reddit metrics vs. stock price and volume</a></li>
<li class="chapter" data-level="5.3.2" data-path="results.html"><a href="results.html#sentiment-analysis-on-reddit-posts-regarding-gme-1"><i class="fa fa-check"></i><b>5.3.2</b> Sentiment analysis on Reddit posts regarding GME</a></li>
<li class="chapter" data-level="5.3.3" data-path="results.html"><a href="results.html#general-publics-interests-on-google"><i class="fa fa-check"></i><b>5.3.3</b> General Public’s interests on Google</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interactive-component.html"><a href="interactive-component.html"><i class="fa fa-check"></i><b>6</b> Interactive component</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interactive-component.html"><a href="interactive-component.html#link-to-the-interactive-map"><i class="fa fa-check"></i><b>6.1</b> Link to the interactive map</a></li>
<li class="chapter" data-level="6.2" data-path="interactive-component.html"><a href="interactive-component.html#descriptions"><i class="fa fa-check"></i><b>6.2</b> Descriptions</a></li>
<li class="chapter" data-level="6.3" data-path="interactive-component.html"><a href="interactive-component.html#instructions-for-using-the-map"><i class="fa fa-check"></i><b>6.3</b> Instructions for using the map</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>7</b> Conclusion</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analysis of stocks discussed in Reddit r/wallstreetbets</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="data-transformation" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Data transformation</h1>
<div id="reddit-data-transformation" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Reddit Data Transformation</h2>
<p>These 2 waves are mainly caused by the discussions in the subreddit group, r/wallstreetbets. Therefore, we have downloaded the Reddit posts that have been posted during these 2 periods and also extend some time before and after the wave. This is because we believe it takes some time for the initial posts to get public attention and then the posts starts to influence the stock price. Also, by including the posts that are slightly after the wave, we can do a comparison during and after the wave to check how big the effects of the posts in the sub-Reddit group on the stock price. Therefore, we have downloaded the data for the whole January, February, May, June and July, which have completely cover the 2 waves and also cover some extension. Also, we have parsed the posts on daily basis, which also helps to show the change over time.</p>
<div id="parse-stock-tickers-from-reddit-posts" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Parse Stock tickers from Reddit posts</h3>
<p>Before starting to do the analysis, we need to find the list of WSB stocks first. the Generally speaking, all the stocks that have been discussed in the r/wallstreetbets subreddit group should be considered as WSB stock. However, given the time frame that we considered is relatively long, which is 5 months, also, the WSBs has caught huge public attention, which also attracted a lot of new redditers. Therefore, there are many people participate in the discussion and the stocks mentioned are quite diversified. In this project, we will only focus on the top 10 stocks that have been mentioned in the posts. In order to find the top 10 most discussed stocks, we created a python script to parse the reddit posts. You can find the code <a href="https://github.com/stellazhangyue/redditWSB/blob/main/scripts/Possible_Tickers_Finder.ipynb">here</a>. We’ll discuss what the script does in the following paragraphs.</p>
<p>In the source data, which are the daily posts csv files, there are 2 columns that may contains the stock information, which are <code>title</code> and <code>selftext</code> respectively. Therefore, we need to first find the stock ticker from these 2 columns. Generally, the stock ticker should start with <code>$</code> and followed by 2 to 4 consecutive upper case letters. However, in the source data, there is no <code>$</code> exists, we cannot get the exact stock data but rather, we can extract out the list of possible stock tickers by extracting all the sub-strings which are consists of 2 to 4 consecutive upper case letters.</p>
<p>We have used regex in python to extract out the list of possible stock tickers from <code>title</code> and <code>selftext</code> respectively for each of the daily reddit csv and then we combine these 2 lists together. However, there might be the case that the possible stock tickers are mentioned by the redditers both in <code>title</code> and <code>selftext</code>. In this case, we define that the possible stock ticker should be considered only once. Therefore, after combining the 2 lists together, we also need to drop duplicates to make sure there is no double count of possible stock ticker from both <code>title</code> and <code>selftext</code>. With that, we can make sure that the count of every possible stock ticker in 1 row is at most 1.</p>
<p>Then, we start to count the possible stock ticker and summarize the count information into a dictionary. For every daily reddit csv, we will get a possible stock ticker count dictionary and combine them together to get the final count dictionary and stored it into the clean data folder.</p>
<p>Now, in r, we can read the file which contains the information of the final possible stock ticker count. Since we are only interested in the top 10 WSB stocks, we need to re-order the data frame according to the word count in descending order.</p>
<p>We noticed that there are some invalid tickers exists in the data frame, but that is expected since there is no perfect way to extract out the stock ticker due to the lack of <code>$</code> in the data source, so we manually go through the data frame and select out the top 10 tickers, which are: <code>GME</code>, <code>AMC</code>, <code>BB</code>,<code>NOK</code>, <code>SND</code>, <code>NAKD</code>, <code>PLTR</code>, <code>CLOV</code>, <code>RETA</code>, <code>MAR</code>, respectively.</p>
</div>
<div id="rwallstreetbets-subreddit-overview" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> r/wallstreetbets Subreddit Overview</h3>
<p>We’d like to get an overview of r/wallstreetbets subreddit’s metrics. We first loaded separate daily posts data files into one data frame, deduplicate the data and then aggregated the data in following steps:</p>
<ul>
<li><p>Covert post create date from unix epoch integer to a Date <code>date_utc</code>.</p></li>
<li><p>Add two new boolean columns <code>contains_amc</code> and <code>contains_gme</code> to indicate whether the title/content contains the stock ticker, ignoring cases.</p></li>
<li><p>Group the data by <code>date_utc</code>, and then use <code>summarise</code> to get aggregated metrics.</p></li>
</ul>
<p>After cleaning, the data frame contains 5 columns and 210 records. We choose to specificly count the number of posts mentioning <code>GME</code> and <code>AMC</code> because we knoe they are the most prominent stocks in this event.</p>
<table>
<thead>
<tr class="header">
<th align="left">Column Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date_utc</td>
<td align="left">Date</td>
<td align="left">post created date</td>
</tr>
<tr class="even">
<td align="left">post_cnt</td>
<td align="left">integer</td>
<td align="left">number of posts</td>
</tr>
<tr class="odd">
<td align="left">distinct_usr_cnt</td>
<td align="left">integer</td>
<td align="left">number of distinct author that created posts</td>
</tr>
<tr class="even">
<td align="left">gme_cnt</td>
<td align="left">integer</td>
<td align="left">number of posts containing GME</td>
</tr>
<tr class="odd">
<td align="left">amc_cnt</td>
<td align="left">integer</td>
<td align="left">number of posts containing AMC</td>
</tr>
</tbody>
</table>
</div>
<div id="reddit-posts-content" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Reddit posts content</h3>
<p>We’d also like to look into the content of the posts to understand what people are discussing on Reddit during the time period of the event. In order to obtain this information, we’d like do word level analysis on the posts’ contend. We cleaned the text data following steps including:</p>
<ul>
<li><p>Filter to posts with <code>score</code> higher than 10.</p></li>
<li><p>Concatenate <code>title</code> and <code>selftext</code> to one single string <code>text</code></p></li>
<li><p>Select columns we needed. i.e. <code>date_utc</code>, <code>text</code></p></li>
<li><p>Load all post content text as a corpus using <code>tm</code> package.</p></li>
<li><p>Convert Latin characters to ASCII.</p></li>
<li><p>Remove double spaces.</p></li>
<li><p>Remove special characters, numbers or punctuation from text.</p></li>
<li><p>Remove common stop words in order to produce meaningful results and avoid the most common frequent words such as “I” or “the”.</p></li>
<li><p>Remove specific stop words in this context, for example: <code>https</code>, <code>www</code>, <code>amp</code>, <code>com</code> etc.</p></li>
</ul>
<div id="frequent-keywords-in-reddit-posts" class="section level4" number="3.1.3.1">
<h4><span class="header-section-number">3.1.3.1</span> Frequent keywords in Reddit posts</h4>
<p>In order to find frequent keywords mentioned in Reddit posts, we created a document term matrix with the <code>TermDocumentMatrix</code> function from the <code>tm</code> package to obtain words counts for each word mentioned. We created a dataframe containing each word mentioned in the post as the first column and their frequency in the second column, it has 36,261 rows:</p>
<table>
<thead>
<tr class="header">
<th align="left">Column Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">word</td>
<td align="left">character</td>
<td align="left">English word appeared in the Reddit posts</td>
</tr>
<tr class="even">
<td align="left">freq</td>
<td align="left">numeric</td>
<td align="left">Number of appearances</td>
</tr>
</tbody>
</table>
</div>
<div id="sentiment-analysis-on-reddit-posts-regarding-gme" class="section level4" number="3.1.3.2">
<h4><span class="header-section-number">3.1.3.2</span> Sentiment Analysis on Reddit Posts regarding GME</h4>
<p>We are also interested in what’s people’s sentiments on the stocks mentioned. We picked <code>GME</code> as the representative, since it’s the most mentioned stock in r/wallstreetbets and the most reported stock in news. We’d like to perform word level sentiment analysis on the posts mentioning GME to get a better understanding of people’s view over the subject. In addition to the cleaning steps mentioned earlier, we further cleaned the data in following steps:</p>
<ul>
<li><p>Filter to posts mention <code>GME</code> in either title or content text.</p></li>
<li><p>Get <a href="https://www.rdocumentation.org/packages/tidytext/versions/0.2.6/topics/stop_words">stop words</a> from <code>tidytext</code> package and remove from data frame</p></li>
</ul>
<p>We then perform a simple sentiment analysis focusing only at the word level. The lexicon we used is <code>nrc</code> by Saif Mohammad and Peter Turney, classifies words into emotions like positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust. We then summarize the data to get the number of words in each sentiment class for each day.</p>
<p>For complete sentiment analysis code, see <a href="https://github.com/stellazhangyue/redditWSB/blob/main/sentiment_analysis.R">here</a>.</p>
<p>We process the Reddit posts one month at a time because of the huge data size and limited memory. In the end we combined the monthly data into two data frames: 1. containing Jan and Feb, corresponding to the time period of first wave; 2. containing May, Jun and Jul, corresponding to the time period of second wave. Each of them has following schema:</p>
<table>
<thead>
<tr class="header">
<th align="left">Column Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">textDate</td>
<td align="left">character</td>
<td align="left">post created date</td>
</tr>
<tr class="even">
<td align="left">sentiment</td>
<td align="left">character</td>
<td align="left">nrc classified sentiment</td>
</tr>
<tr class="odd">
<td align="left">wordCount</td>
<td align="left">numeric</td>
<td align="left">number of words in the sentiment class</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="stock-data-transformation" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Stock Data Transformation</h2>
<p>For each of the top 10 mentioned tickers, we download its stock price data from <a href="https://finance.yahoo.com/"><em>Yahoo Finance</em></a> using <code>quantmod</code> package for the time period starting from 2020-01-01. The data downloaded by using <code>quantmod</code> are <code>xts</code> <code>zoo</code> objects and each object has following attributes: <code>X.Open</code>,<code>X.High</code>,<code>X.Low</code>,<code>X.Close</code>,<code>X.Volume</code>,<code>X.Adjusted</code> where <code>X</code> is the stock ticker. We transformed each of those objects to the format we need in following steps:</p>
<ul>
<li><p>Convert <code>xts</code> <code>zoo</code> object to <code>data.frame</code>, by loading <code>index</code> to <code>Date</code> column and extracting the core data.</p></li>
<li><p>Select columns we needed. i.e.<code>Date</code>, <code>X.Close</code> and <code>X.Volume</code>.</p></li>
<li><p>Rename <code>X.Close</code> as <code>Close</code>, <code>X.Volume</code> as <code>Volume</code>.</p></li>
<li><p>Add a <code>Symbol</code> column to indicate the ticker.</p></li>
</ul>
<p>After finishing downloading data for all 10 tickers, we bind them to one big data frame containing all data, which has 3 columns and 4956 rows:</p>
<table>
<thead>
<tr class="header">
<th align="left">Column Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Symbol</td>
<td align="left">character</td>
<td align="left">Date of the prices and volume</td>
</tr>
<tr class="even">
<td align="left">Date</td>
<td align="left">Date</td>
<td align="left">Stock ticker</td>
</tr>
<tr class="odd">
<td align="left">Close</td>
<td align="left">numeric</td>
<td align="left">Close price adjusted for splits</td>
</tr>
<tr class="even">
<td align="left">Volume</td>
<td align="left">numeric</td>
<td align="left">Number of shares traded</td>
</tr>
</tbody>
</table>
<p>Looking at the raw price might not be as useful when comparing different stocks because they have different volume. It is useful to look at change in price instead. We can calculate the aggregated return in percentage by using function <code>periodReturn</code>. The aggregate level can be specified by changing argument <code>period</code>. Here we set the aggregate level to be <code>daily</code>. Similar to how we handle the price and volume, for each ticker we performed following steps to get the data in the format we need:</p>
<ul>
<li><p>Download stock price data using <code>quantmod</code> package</p></li>
<li><p>Apply <code>periodReturn</code> function with <code>period="daily"</code> to calculate daily return</p></li>
<li><p>Convert <code>xts</code> <code>zoo</code> object to <code>data.frame</code>, by loading <code>index</code> to <code>Date</code> column and <code>daily.returns</code>.</p></li>
<li><p>Multiply the calculated daily return by 100 to concert to percentage</p></li>
<li><p>Rename <code>daily.returns</code> as <code>Daily_return</code>.</p></li>
<li><p>Add a <code>Symbol</code> column to indicate the ticker.</p></li>
<li><p>Select columns we needed. i.e.<code>Date</code>, <code>Daily_return</code> and <code>Symbol</code>.</p></li>
</ul>
<p>After finishing downloading and processing data for all 10 tickers, we bind them to one big data frame containing all data, which has 4 columns and 4956 rows:</p>
<table>
<thead>
<tr class="header">
<th align="left">Column Name</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Symbol</td>
<td align="left">character</td>
<td align="left">Date of the prices and volume</td>
</tr>
<tr class="even">
<td align="left">Date</td>
<td align="left">Date</td>
<td align="left">Stock ticker</td>
</tr>
<tr class="odd">
<td align="left">Daily_return</td>
<td align="left">numeric</td>
<td align="left">Daily return in percentage</td>
</tr>
</tbody>
</table>
</div>
<div id="google-trends-data-transformation" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Google Trends Data Transformation</h2>
<p>In the Google Trends source data, it assigns a number to each keyword for each period(week). The numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. A score of 0 means there was not enough data for this term. A score of &lt;1 means there is some search interest but it’s extremely low. We are replacing all &lt;1’s with 0.5, so that we can keep the data frame consistent with all scores as numeric data.</p>
<p>We also need to tidy the dataset because some of the column names are not names of variables, but values of a variable: the original column names represent the values of the <code>keyword</code> variable and the values in the columns represents the values of <code>score</code>, and each row represents 5 observations, not one. To tidy the dataset, we make the offending columns into a new pair of variables using <code>pivot_longer</code>.</p>
<p>After cleaning, it contains 3 rows and 260 records.</p>
<table>
<thead>
<tr class="header">
<th align="left">Column</th>
<th align="left">Type</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">week</td>
<td align="left">date</td>
<td align="left">Which week?</td>
</tr>
<tr class="even">
<td align="left">keyword</td>
<td align="left">string</td>
<td align="left">Search keyword</td>
</tr>
<tr class="odd">
<td align="left">score</td>
<td align="left">numeric</td>
<td align="left">Search interest score</td>
</tr>
</tbody>
</table>
<p>References:</p>
<ol style="list-style-type: decimal">
<li><p>How to Generate Word Clouds in R (<a href="https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a" class="uri">https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a</a>)</p></li>
<li><p>Tutorial: Sentiment Analysis in R(<a href="https://www.kaggle.com/rtatman/tutorial-sentiment-analysis-in-r" class="uri">https://www.kaggle.com/rtatman/tutorial-sentiment-analysis-in-r</a>)</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-sources.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="missing-values.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/stellazhangyue/redditWSB/edit/main/03-cleaning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/stellazhangyue/redditWSB/blob/main/03-cleaning.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
